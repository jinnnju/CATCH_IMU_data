{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "normal = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz.csv', skiprows=1, on_bad_lines=\"skip\")  \n",
    "abnormal0 = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz(500g).csv',skiprows=1, on_bad_lines=\"skip\")\n",
    "abnormal1 = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz(1kg).csv', skiprows=1, on_bad_lines=\"skip\")\n",
    "abnormal2 = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz(2kg).csv', skiprows=1, on_bad_lines=\"skip\")\n",
    "abnormal3 = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz(inner).csv', skiprows=1, on_bad_lines=\"skip\")\n",
    "abnormal4 = pd.read_csv('/home/work/Climate_map/CATCH/IMU_data/Beanpicking/Beanpicking_imu_data_250Hz(outer).csv', skiprows=1, on_bad_lines=\"skip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def IMU_to_CATCH(a_0: pd.DataFrame,\n",
    "#                                a_1: pd.DataFrame,\n",
    "#                                out_path: str,\n",
    "#                                time_col: str = \"timestamp\",\n",
    "#                                cumulative_date: bool = False) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     a_0, a_1의 열 셋이 같다는 전제하에,\n",
    "#     '컬럼 단위'로 묶어 (col별로 a_0 전부 → a_1 전부) 쌓아\n",
    "#     long 포맷(date, data, cols)으로 저장.\n",
    "\n",
    "#     - 행 수는 달라도 OK\n",
    "#     - date: 기본은 각 블록(a_0, a_1)에서 1..N 재시작\n",
    "#             cumulative_date=True면 a_1이 a_0의 다음 번호로 이어짐\n",
    "#     - 마지막에 label 컬럼(문자 그대로)을 추가:\n",
    "#         a_0 길이만큼 0, a_1 길이만큼 1\n",
    "#     \"\"\"\n",
    "#     def value_cols(df: pd.DataFrame) -> list:\n",
    "#         cols = df.columns.tolist()\n",
    "#         if time_col in cols:\n",
    "#             cols.remove(time_col)\n",
    "#         return cols\n",
    "\n",
    "#     cols0, cols1 = value_cols(a_0), value_cols(a_1)\n",
    "#     if set(cols0) != set(cols1):\n",
    "#         raise ValueError(\n",
    "#             \"Columns must match.\\n\"\n",
    "#             f\"Missing in a_1: {[c for c in cols0 if c not in cols1]}\\n\"\n",
    "#             f\"Missing in a_0: {[c for c in cols1 if c not in cols0]}\"\n",
    "#         )\n",
    "\n",
    "#     # a_0의 컬럼 순서를 기준으로\n",
    "#     cols = cols0\n",
    "#     a0_len, a1_len = len(a_0), len(a_1)\n",
    "\n",
    "#     parts = []\n",
    "\n",
    "#     for col in cols:\n",
    "#         s0 = a_0[col].to_numpy()\n",
    "#         s1 = a_1[col].to_numpy()\n",
    "\n",
    "#         if cumulative_date:\n",
    "#             date0 = np.arange(1, a0_len + 1)\n",
    "#             date1 = np.arange(a_0.shape[0] + 1, a_0.shape[0] + a_1.shape[0] + 1)\n",
    "#         else:\n",
    "#             date0 = np.arange(1, a0_len + 1)\n",
    "#             date1 = np.arange(1, a1_len + 1)\n",
    "\n",
    "#         df0 = pd.DataFrame({\"date\": date0, \"data\": s0, \"cols\": col})\n",
    "#         df1 = pd.DataFrame({\"date\": date1, \"data\": s1, \"cols\": col})\n",
    "#         parts.extend([df0, df1])  # col 하나에 대해 a_0 전체 → a_1 전체\n",
    "\n",
    "#     # label 컬럼 추가 (문자 그대로 'label')\n",
    "#     if cumulative_date:\n",
    "#         l0_date = np.arange(1, a0_len + 1)\n",
    "#         l1_date = np.arange(a0_len + 1, a0_len + a1_len + 1)\n",
    "#     else:\n",
    "#         l0_date = np.arange(1, a0_len + 1)\n",
    "#         l1_date = np.arange(1, a1_len + 1)\n",
    "\n",
    "#     label0 = pd.DataFrame({\"date\": l0_date, \"data\": 0, \"cols\": \"label\"})\n",
    "#     label1 = pd.DataFrame({\"date\": l1_date, \"data\": 1, \"cols\": \"label\"})\n",
    "\n",
    "#     final_df = pd.concat(parts + [label0, label1], ignore_index=True)\n",
    "#     final_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "#     return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def IMU_to_CATCH(a_0: pd.DataFrame,\n",
    "                 a_1: pd.DataFrame,\n",
    "                 out_path: str,\n",
    "                 time_col: str = \"timestamp\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    두 DF(a_0, a_1)의 컬럼명이 동일하다는 전제하에,\n",
    "    (1) 컬럼명 사전순으로 정렬,\n",
    "    (2) 각 컬럼별로 a_0 전구간을 먼저, 이어서 a_1 전구간을 쌓고,\n",
    "    (3) date 인덱스는 a_0→a_1로 '연속'(1..len(a_0)+len(a_1))이 되도록 부여,\n",
    "    (4) 마지막에 label(문자 그대로) 행 추가: a_0 구간 0, a_1 구간 1,\n",
    "    형태의 long 포맷(date, data, cols) CSV를 저장한다.\n",
    "    \"\"\"\n",
    "    # 값 컬럼 선택(시간열이 있으면 제외)\n",
    "    def value_cols(df: pd.DataFrame) -> list:\n",
    "        cols = [c for c in df.columns if c != time_col]\n",
    "        # 컬럼명 사전순 정렬\n",
    "        cols.sort()\n",
    "        return cols\n",
    "\n",
    "    cols0 = value_cols(a_0)\n",
    "    cols1 = value_cols(a_1)\n",
    "    if set(cols0) != set(cols1):\n",
    "        raise ValueError(\n",
    "            \"Columns must match.\\n\"\n",
    "            f\"Missing in a_1: {[c for c in cols0 if c not in cols1]}\\n\"\n",
    "            f\"Missing in a_0: {[c for c in cols1 if c not in cols0]}\"\n",
    "        )\n",
    "\n",
    "    cols = cols0  # 정렬된 공통 컬럼 목록\n",
    "    n0, n1 = len(a_0), len(a_1)\n",
    "    total_len = n0 + n1\n",
    "\n",
    "    # 연속 date 인덱스 (전 컬럼 공통)\n",
    "    date0 = np.arange(1, n0 + 1)                 # a_0 구간\n",
    "    date1 = np.arange(n0 + 1, n0 + n1 + 1)       # a_1 구간\n",
    "\n",
    "    parts = []\n",
    "    for col in cols:\n",
    "        s0 = a_0[col].to_numpy()\n",
    "        s1 = a_1[col].to_numpy()\n",
    "        df0 = pd.DataFrame({\"date\": date0, \"data\": s0, \"cols\": col})\n",
    "        df1 = pd.DataFrame({\"date\": date1, \"data\": s1, \"cols\": col})\n",
    "        parts.extend([df0, df1])  # (a_0 → a_1) 순서\n",
    "\n",
    "    # label 컬럼 추가 (문자 그대로 'label')\n",
    "    label0 = pd.DataFrame({\"date\": date0, \"data\": 0, \"cols\": \"label\"})\n",
    "    label1 = pd.DataFrame({\"date\": date1, \"data\": 1, \"cols\": \"label\"})\n",
    "\n",
    "    final_df = pd.concat(parts + [label0, label1], ignore_index=True)\n",
    "    final_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date      data     cols\n",
      "0     1 -0.000000  accel_x\n",
      "1     2  0.130892  accel_x\n",
      "2     3  0.130892  accel_x\n",
      "3     4  0.138058  accel_x\n",
      "4     5  0.107008  accel_x\n"
     ]
    }
   ],
   "source": [
    "# a_0, a_1이 이미 로드된 상태라고 가정\n",
    "df_long =  IMU_to_CATCH(normal, abnormal2, out_path=\"/home/work/Climate_map/CATCH/dataset/anomaly_detect/data/IMU.csv\", time_col=\"timestamp\")\n",
    "print(df_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.130892</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.130892</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.138058</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.107008</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744028</th>\n",
       "      <td>749537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744029</th>\n",
       "      <td>749538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744030</th>\n",
       "      <td>749539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744031</th>\n",
       "      <td>749540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744032</th>\n",
       "      <td>749541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9744033 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      data     cols\n",
       "0             1 -0.000000  accel_x\n",
       "1             2  0.130892  accel_x\n",
       "2             3  0.130892  accel_x\n",
       "3             4  0.138058  accel_x\n",
       "4             5  0.107008  accel_x\n",
       "...         ...       ...      ...\n",
       "9744028  749537  1.000000    label\n",
       "9744029  749538  1.000000    label\n",
       "9744030  749539  1.000000    label\n",
       "9744031  749540  1.000000    label\n",
       "9744032  749541  1.000000    label\n",
       "\n",
       "[9744033 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.061626</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.080734</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.161943</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.145223</td>\n",
       "      <td>accel_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338591</th>\n",
       "      <td>71973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338592</th>\n",
       "      <td>71974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338593</th>\n",
       "      <td>71975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338594</th>\n",
       "      <td>71976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338595</th>\n",
       "      <td>71977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2338596 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      data     cols\n",
       "0            1 -0.000000  accel_x\n",
       "1            2  0.061626  accel_x\n",
       "2            3  0.080734  accel_x\n",
       "3            4  0.161943  accel_x\n",
       "4            5  0.145223  accel_x\n",
       "...        ...       ...      ...\n",
       "2338591  71973  1.000000    label\n",
       "2338592  71974  1.000000    label\n",
       "2338593  71975  1.000000    label\n",
       "2338594  71976  1.000000    label\n",
       "2338595  71977  1.000000    label\n",
       "\n",
       "[2338596 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 파일 안: ['CATCH.1755567637.main1.3739625.csv']\n",
      "  model_name                                      strategy_args  \\\n",
      "0      CATCH  {\"seed\": 2021, \"strategy_name\": \"unfixed_detec...   \n",
      "\n",
      "                                        model_params  accuracy   f_score  \\\n",
      "0  {\"Mlr\": 1e-05, \"anomaly_ratio\": 5.0, \"auxi_lam...  0.456407  0.090786   \n",
      "\n",
      "   precision    recall  adjust_accuracy  adjust_f_score  adjust_precision  \\\n",
      "0   0.519706  0.049737         0.974919        0.977534          0.956055   \n",
      "\n",
      "   ...  affiliation_f  affiliation_precision  affiliation_recall  file_name  \\\n",
      "0  ...       0.772598               0.629544            0.999781    IMU.csv   \n",
      "\n",
      "     fit_time  inference_time  typical_anomaly_ratio  actual_data  \\\n",
      "0  974.271445      926.126641                    5.0          NaN   \n",
      "\n",
      "  inference_data  log_info  \n",
      "0            NaN       NaN  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "tar_path = \"/home/work/Climate_map/CATCH/result/label/CATCH/CATCH.1755567637.main1.3739625.csv.tar.gz\"\n",
    "\n",
    "# tar.gz 열기\n",
    "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "    # 압축 안에 있는 파일 목록 확인\n",
    "    members = tar.getnames()\n",
    "    print(\"압축 파일 안:\", members)\n",
    "\n",
    "    # 첫 번째 CSV 파일만 읽어오기 (여러 개면 원하는 파일 선택)\n",
    "    csv_name = members[0]\n",
    "    with tar.extractfile(csv_name) as f:\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "        \n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy_args</th>\n",
       "      <th>model_params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>adjust_accuracy</th>\n",
       "      <th>adjust_f_score</th>\n",
       "      <th>adjust_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>affiliation_f</th>\n",
       "      <th>affiliation_precision</th>\n",
       "      <th>affiliation_recall</th>\n",
       "      <th>file_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>typical_anomaly_ratio</th>\n",
       "      <th>actual_data</th>\n",
       "      <th>inference_data</th>\n",
       "      <th>log_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATCH</td>\n",
       "      <td>{\"seed\": 2021, \"strategy_name\": \"unfixed_detec...</td>\n",
       "      <td>{\"Mlr\": 1e-05, \"anomaly_ratio\": 5.0, \"auxi_lam...</td>\n",
       "      <td>0.456407</td>\n",
       "      <td>0.090786</td>\n",
       "      <td>0.519706</td>\n",
       "      <td>0.049737</td>\n",
       "      <td>0.974919</td>\n",
       "      <td>0.977534</td>\n",
       "      <td>0.956055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772598</td>\n",
       "      <td>0.629544</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>IMU.csv</td>\n",
       "      <td>974.271445</td>\n",
       "      <td>926.126641</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name                                      strategy_args  \\\n",
       "0      CATCH  {\"seed\": 2021, \"strategy_name\": \"unfixed_detec...   \n",
       "\n",
       "                                        model_params  accuracy   f_score  \\\n",
       "0  {\"Mlr\": 1e-05, \"anomaly_ratio\": 5.0, \"auxi_lam...  0.456407  0.090786   \n",
       "\n",
       "   precision    recall  adjust_accuracy  adjust_f_score  adjust_precision  \\\n",
       "0   0.519706  0.049737         0.974919        0.977534          0.956055   \n",
       "\n",
       "   ...  affiliation_f  affiliation_precision  affiliation_recall  file_name  \\\n",
       "0  ...       0.772598               0.629544            0.999781    IMU.csv   \n",
       "\n",
       "     fit_time  inference_time  typical_anomaly_ratio  actual_data  \\\n",
       "0  974.271445      926.126641                    5.0          NaN   \n",
       "\n",
       "  inference_data  log_info  \n",
       "0            NaN       NaN  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh ./scripts/multivariate_detection/detect_label/IMU_script/CATCH.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
